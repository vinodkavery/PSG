# ğŸ® PSG â€” When to insert an Ad?

### ğŸ§  Objective

This project simulates a **mobile gaming environment** and applies **machine learning** to optimize **ad-serving decisions** â€” deciding *when to show or skip an ad* to **maximize revenue** while **minimizing churn risk**.

---

## ğŸ“ Repository Structure

| File                                   | Description                                                                                                                                                                |
| -------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ğŸ“˜ **`PSG_Ad_DataGen.ipynb`**          | Generates a **synthetic dataset** of player sessions, ad exposures, engagement, and monetization metrics based on realistic 2025 gaming benchmarks.                        |
| ğŸ¤– **`PSG_Ad_Models_102125_v3.ipynb`** | Trains and evaluates **machine learning models** (classification & contextual bandit preparation) to predict optimal ad-serving actions that balance **reward vs. churn**. |
| ğŸ“„ **`requirements.txt`**              | Lists all Python dependencies required to run both notebooks.                                                                                                              |
                                                                                                                            |

---

## ğŸ§© 1. Data Generation â€” `PSG_Ad_DataGen.ipynb`

### ğŸ“‹ Description

Creates a **simulated playerâ€“sessionâ€“ad dataset** reflecting realistic puzzle gaming dynamics.

**Simulated features include:**

* ğŸ® `session_duration` â†’ 5â€“15 minutes
* ğŸ“º `ads_shown_per_session` â†’ 2â€“5 ads
* âš ï¸ `churn_probability` â†’ 20â€“30%
* ğŸ’° `ad_revenue_per_impression` â†’ $0.001â€“$0.015
* ğŸ§® `click_rate`, `ARPDAU`, `LTV`, `retention_rate`

**Output:**
A CSV file where each row = one userâ€“sessionâ€“ad interaction, ready for modeling.

---

## ğŸ¤– 2. Model Training & Evaluation â€” `PSG_Ad_Models_102125_v3.ipynb`

### âš™ï¸ Description

Trains ML models on the synthetic dataset to **predict churn or reward** outcomes, given user and gameplay context.

**Key Steps:**

1. Data preprocessing â€” scaling, encoding, and imputation
2. Model training â€” Logistic Regression, XGBoost, or Neural models
3. Evaluation metrics:

   * ğŸ§¾ ROC-AUC
   * ğŸ“ˆ Average Precision
   * ğŸ¯ Precisionâ€“Recall Curve
   * ğŸ“Š Calibration curve
4. Future-ready structure for **Contextual Bandit / Policy Optimization**.

**Optimization Goal:**
Formulate a policy Ï€(*state â†’ action*) that maximizes:

> ğŸ’¡ **Expected Reward = Revenue_if_Shown â€“ (Churn_Risk Ã— LTV)**

---

## ğŸ§± Setup Instructions

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/<your-username>/playsimple-ad-optimization.git
cd playsimple-ad-optimization
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # macOS/Linux
venv\Scripts\activate      # Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run Notebooks

```bash
jupyter notebook
```

Then open and run:

* `PSG_Ad_DataGen.ipynb` â†’ to generate the dataset
* `PSG_Ad_Models_102125_v3.ipynb` â†’ to train and evaluate models

---

## ğŸ§¾ Dependencies

See [`requirements.txt`](./requirements.txt) for the complete list.
**Core libraries:**

* `pandas`, `numpy`, `scikit-learn`
* `torch`, `xgboost`, `imblearn`
* `matplotlib`, `seaborn`, `ipython`, `scipy`

---

## ğŸš€ Future Extensions

* ğŸ§  Integrate **Reinforcement Learning / Multi-Armed Bandit** algorithms
* ğŸ” Add **live A/B testing simulation**
* ğŸ“ˆ Visualize **policy learning curves** and **rewardâ€“churn trade-offs**

---

## ğŸ‘¤ Author

**Vinod Kumar K**
*PSG â€“ Ad Optimization Assignment (2025)*


---
